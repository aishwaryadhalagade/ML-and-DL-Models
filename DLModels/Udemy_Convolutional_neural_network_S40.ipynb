{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Udemy_Convolutional_neural_network_S40.ipynb","provenance":[{"file_id":"1Y-a4g98w93GHswXLRLoiogvMYNPgzPE9","timestamp":1598338478612}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu","colab_type":"text"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"EMefrVPCg-60","colab_type":"text"},"source":["### Importing the libraries"]},{"cell_type":"code","metadata":{"id":"hohB1EgYct3y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598339950437,"user_tz":420,"elapsed":4072,"user":{"displayName":"Aishwarya Dhalagade","photoUrl":"","userId":"15131201790684589449"}}},"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"QiLCVfo6e5lM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598339956791,"user_tz":420,"elapsed":3796,"user":{"displayName":"Aishwarya Dhalagade","photoUrl":"","userId":"15131201790684589449"}},"outputId":"8d0937d6-f9f0-42ef-c401-f7d9b8b30f62"},"source":["tf.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.3.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE","colab_type":"text"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"MvE-heJNo3GG","colab_type":"text"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","metadata":{"id":"l2UsUA5tkqFH","colab_type":"code","colab":{}},"source":["# we apply some transformation on tranining set in order to avoid overfitting on training set\n","# Hence we do image augmentation on training set\n","\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255,                                           # rescale is nothing but feature scaling,these apply feature scaling to each one of your image pixels by dividing their value by 255(1 to 256),hence we get all the pixel values between 0 and 1\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","training_set = train_datagen.flow_from_directory(                # here we connect the given augmentated images(dataset) method to our main training dataset\n","        'dataset/training_set',\n","        target_size=(64, 64),                                    # its nothing but image size,batch size while going into convolutional layer\n","        batch_size=32,\n","        class_mode='binary')                                    # binary of categorical"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mrCMmGw9pHys","colab_type":"text"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","metadata":{"id":"O8lGXxhukvPS","colab_type":"code","colab":{}},"source":["test_datagen = ImageDataGenerator(rescale=1./255)                 # here we do same feature scaling as we did for training set \n","test_set = test_datagen.flow_from_directory(\n","        'dataset/test_set',\n","        target_size=(64, 64),\n","        batch_size=32,\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B","colab_type":"text"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX","colab_type":"text"},"source":["### Initialising the CNN"]},{"cell_type":"code","metadata":{"id":"Zkhi64aJno7Y","colab_type":"code","colab":{}},"source":["cnn = tf.keras.models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF","colab_type":"text"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","metadata":{"id":"HPNkVOxYnz4E","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3]))\n","\n","# Here filter means feature detector or feature mapping,we use 32 filters here\n","# size of keranl means size of feature detector ie 3*3 = 3\n","# input shape = [64,64,3]  - (64,64) is same as applied before convolutional layer passing to images, and 3 is for colored image, where for black and white imags we use 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ","colab_type":"text"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","metadata":{"id":"BRW5LZM5qURy","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size= 2, strides= 2)\n","\n","# pool size means the frame size while doing max pooling ie 2*2 block\n","# strides means shifting of that frame 2 pixel ie to the next frame not 1 by 1 to each block but by 2 pixel"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU","colab_type":"text"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","metadata":{"id":"9loQuL31sxi1","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', ))          # here we dont take input_shape parameter bcoz its only added in first convultional layer as we get image from input directly,but there is no need to apply while building second convolutional layer\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size= 2, strides= 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk","colab_type":"text"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","metadata":{"id":"UTvGZtOntvJh","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Flatten())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v","colab_type":"text"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","metadata":{"id":"UHV_TxHMuJhf","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Dense(units= 128, activation= 'relu'))\n","\n","# here we are building Artificial neural network which is called fully connected layers and connected to cnn model after flattening, hence we use Dense class same as ann model(we used for it before)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na","colab_type":"text"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","metadata":{"id":"DNmyBtDNvJEi","colab_type":"code","colab":{}},"source":["cnn.add(tf.keras.layers.Dense(units= 1, activation= 'sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl","colab_type":"text"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i","colab_type":"text"},"source":["### Compiling the CNN"]},{"cell_type":"code","metadata":{"id":"GE7U5tBa8LCW","colab_type":"code","colab":{}},"source":["cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h","colab_type":"text"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","metadata":{"id":"hTrtOktM9odm","colab_type":"code","colab":{}},"source":["cnn.fit(X = training_set, validation_data = test_set, epochs = 25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3PZasO0006Z","colab_type":"text"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","metadata":{"id":"limP5WHb-yNb","colab_type":"code","colab":{}},"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64,64))\n","test_image = image.img_to_array(test_image)                                       # predict method expects its input in 2D array format,hence convert image (PIL) into array format\n","test_image = np.expand_dims(test_image, axis = 0)                             # here we gonna put the image which we are predicting in the batch( as training is done on batches,hence prediction should also be on it), and here dimension of the batch which we are adding our image will be the first dimension(0th)\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1:                                         # [0][0] - batch of 0th order and in that batch image is only one to predict hence 0th image\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sr6bELj5Edz_","colab_type":"code","colab":{}},"source":["print(prediction)"],"execution_count":null,"outputs":[]}]}